{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setting Parameters",
   "id": "eb6a771df89ae637"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "apply_classes = ['33+1', '8+1', '1+1']\n",
    "\n",
    "apply_sampling = None   # DO NOT CHANGE\n",
    "\n",
    "apply_evaluators = ['Perceptron', 'XGBoost', 'KNearestNeighbor', 'RandomForest']\n",
    "\n",
    "\n",
    "# Checking that inputs are available\n",
    "for _class in apply_classes:\n",
    "    if _class not in ['33+1', '8+1', '1+1']:\n",
    "        assert False, f'{_class} is an invalid class structure.'\n",
    "\n",
    "if apply_sampling not in [None, 'RandomOverSampler', 'RandomUnderSampler', 'SMOTE', 'Cluster+SMOTE']:\n",
    "    assert False, f'{apply_sampling} is an invalid under-sampler.'\n",
    "\n",
    "for evaluator in apply_evaluators:\n",
    "    if evaluator not in ['XGBoost', 'LogisticRegression', 'Perceptron', 'AdaBoost', \n",
    "                         'RandomForest', 'DeepNeuralNetwork', 'KNearestNeighbor']:\n",
    "        assert False, f'{evaluator} is an invalid evaluator.'"
   ],
   "id": "74ccfb5aec085650",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset Handling\n",
    "## Imports"
   ],
   "id": "92b5ca862026ccb8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a7571b3fb052a635"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading the Dataset",
   "id": "7800077eb66afa24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATASET_DIRECTORY = '../../dataset/'  # If your dataset is within your python project directory, change this to the relative path to your dataset\n",
    "csv_filepaths = [filename for filename in os.listdir(DATASET_DIRECTORY) if filename.endswith('.csv')]\n",
    "\n",
    "print(csv_filepaths)\n",
    "\n",
    "# If there are more than X CSV files, randomly select X files from the list\n",
    "sample_size = 5\n",
    "\n",
    "if len(csv_filepaths) > sample_size:\n",
    "    csv_filepaths = random.sample(csv_filepaths, sample_size)\n",
    "    print(csv_filepaths)\n",
    "\n",
    "csv_filepaths.sort()\n",
    "\n",
    "# list of csv files used\n",
    "data_sets = csv_filepaths\n",
    "\n",
    "full_data = pd.DataFrame()\n",
    "for data_set in data_sets:\n",
    "    print(f\"data set {data_set} out of {len(data_sets)} \\n\")\n",
    "    data_path = os.path.join(DATASET_DIRECTORY, data_set)\n",
    "    df = pd.read_csv(data_path)\n",
    "    full_data = pd.concat([full_data, df])\n",
    "\n",
    "# prints an instance of each class\n",
    "print(\"Before encoding:\")\n",
    "unique_labels = full_data['label'].unique()\n",
    "for label in unique_labels:\n",
    "    print(f\"First instance of {label}:\")\n",
    "    print(full_data[full_data['label'] == label].iloc[0])\n",
    "\n",
    "# Shuffle data\n",
    "full_data = shuffle(full_data, random_state=1)\n",
    "\n",
    "# prove if the data is loaded properly\n",
    "print(\"Real data:\")\n",
    "print(full_data[:2])\n",
    "print(full_data.shape)\n",
    "\n",
    "# Assuming 'label' is the column name for the labels in the DataFrame `synth_data`\n",
    "unique_labels = full_data['label'].nunique()\n",
    "\n",
    "# Print the number of unique labels\n",
    "print(f\"There are {unique_labels} unique labels in the dataset.\")\n",
    "\n",
    "class_counts = full_data['label'].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "# Display the first few entries to verify the changes\n",
    "full_data.describe()"
   ],
   "id": "eb8d1409f0905107",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Preprocessing\n",
    "## Encoding Labels"
   ],
   "id": "41752811a0f0f877"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "full_data['33+1'] = full_data['label'].copy()\n",
    "\n",
    "label_categories = {\n",
    "    'Backdoor_Malware': 'Web',\n",
    "    'BenignTraffic': 'Benign',\n",
    "    'BrowserHijacking': 'Web',\n",
    "    'CommandInjection': 'DDoS',\n",
    "    'DDoS-ACK_Fragmentation': 'DDoS',\n",
    "    'DDoS-HTTP_Flood': 'DDoS',\n",
    "    'DDoS-ICMP_Flood': 'DDoS',\n",
    "    'DDoS-ICMP_Fragmentation': 'DDoS',\n",
    "    'DDoS-PSHACK_Flood': 'DDoS',\n",
    "    'DDoS-RSTFINFlood': 'DDoS',\n",
    "    'DDoS-SYN_Flood': 'DDoS',\n",
    "    'DDoS-SlowLoris': 'DDoS',\n",
    "    'DDoS-SynonymousIP_Flood': 'DDoS',\n",
    "    'DDoS-TCP_Flood': 'DDoS',\n",
    "    'DDoS-UDP_Flood': 'DDoS',\n",
    "    'DDoS-UDP_Fragmentation': 'DDoS',\n",
    "    'DNS_Spoofing': 'Spoofing',\n",
    "    'DictionaryBruteForce': 'BruteForce',\n",
    "    'DoS-HTTP_Flood': 'DoS',\n",
    "    'DoS-SYN_Flood': 'DoS',\n",
    "    'DoS-TCP_Flood': 'DoS',\n",
    "    'DoS-UDP_Flood': 'DoS',\n",
    "    'MITM-ArpSpoofing': 'Spoofing',\n",
    "    'Mirai-greeth_flood': 'Mirai',\n",
    "    'Mirai-greip_flood': 'Mirai',\n",
    "    'Mirai-udpplain': 'Mirai',\n",
    "    'Recon-HostDiscovery': 'Recon',\n",
    "    'Recon-OSScan': 'Recon',\n",
    "    'Recon-PingSweep': 'Recon',\n",
    "    'Recon-PortScan': 'Recon',\n",
    "    'SqlInjection': 'Web',\n",
    "    'Uploading_Attack': 'Web',\n",
    "    'VulnerabilityScan': 'Recon',\n",
    "    'XSS': 'Web'\n",
    "}\n",
    "full_data['8+1'] = full_data['33+1'].map(label_categories)\n",
    "\n",
    "full_data.loc[full_data['label'] != 'BenignTraffic', '1+1'] = 'Attack'\n",
    "full_data.loc[full_data['label'] == 'BenignTraffic', '1+1'] = 'Benign'\n",
    "\n",
    "full_label_encoder = LabelEncoder()\n",
    "class_label_encoder = LabelEncoder()\n",
    "binary_label_encoder = LabelEncoder()\n",
    "\n",
    "full_data['33+1'] = full_label_encoder.fit_transform(full_data['33+1'])\n",
    "full_data['8+1'] = class_label_encoder.fit_transform(full_data['8+1'])\n",
    "full_data['1+1'] = binary_label_encoder.fit_transform(full_data['1+1'])\n",
    "\n",
    "# Store label mappings\n",
    "label_mapping = {index: label for index, label in enumerate(full_label_encoder.classes_)}\n",
    "print(\"Label mappings:\", label_mapping)\n",
    "\n",
    "# Retrieve the numeric codes for classes\n",
    "class_codes = {label: full_label_encoder.transform([label])[0] for label in full_label_encoder.classes_}\n",
    "\n",
    "# Print specific instances after label encoding\n",
    "print(\"After encoding:\")\n",
    "for label, code in class_codes.items():\n",
    "    # Print the first instance of each class\n",
    "    print(f\"First instance of {label} (code {code}):\")\n",
    "    print(full_data[full_data['33+1'] == code].iloc[0])\n",
    "\n",
    "full_data.head()"
   ],
   "id": "deb73c3fa50d313a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ",
   "id": "7d94ad5ba77c9703"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = full_data.drop(['label', '33+1', '8+1', '1+1'], axis=1)\n",
    "y = full_data[['label', '33+1', '8+1', '1+1']]"
   ],
   "id": "b009b62ac38de34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sampling",
   "id": "2f03f85405da6e1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if apply_sampling is not None:\n",
    "    cat_cols = [\n",
    "        'Protocol Type', 'Drate', 'fin_flag_number', 'syn_flag_number', 'rst_flag_number',\n",
    "        'psh_flag_number', 'ack_flag_number', 'ece_flag_number',\n",
    "        'cwr_flag_number', 'HTTP', 'HTTPS', 'DNS', 'Telnet',\n",
    "        'SMTP', 'SSH', 'IRC', 'TCP', 'UDP', 'DHCP', 'ARP',\n",
    "        'ICMP', 'IPv', 'LLC'\n",
    "    ]\n",
    "    \n",
    "    undersampler = None\n",
    "    oversampler = None\n",
    "    \n",
    "    match apply_sampling:\n",
    "        case 'RandomOverSampler':\n",
    "            from imblearn.over_sampling import RandomOverSampler\n",
    "            oversampler = RandomOverSampler(random_state=42)\n",
    "        case 'RandomUnderSampler':\n",
    "            from imblearn.under_sampling import RandomUnderSampler\n",
    "            undersampler = RandomUnderSampler(random_state=42)\n",
    "        case 'SMOTENC':\n",
    "            from imblearn.over_sampling import SMOTENC\n",
    "            oversampler = SMOTENC(categorical_features=cat_cols, random_state=42)\n",
    "        case 'Clustering+SMOTENC':\n",
    "            from imblearn.under_sampling import ClusterCentroids\n",
    "            from imblearn.over_sampling import SMOTENC\n",
    "            undersampler = ClusterCentroids(random_state=42)\n",
    "            oversampler = SMOTENC(categorical_features=cat_cols, random_state=42)\n",
    "\n",
    "#   Resampling does not yet include 33+1, 8+1, 1+1 classes\n",
    "#\n",
    "#    if undersampler is not None:\n",
    "#        X, y = undersampler.fit_resample(X, y)  \n",
    "#    if oversampler is not None:\n",
    "#        X, y = oversampler.fit_resample(X, y)\n",
    "        \n",
    "else:\n",
    "    print('No sampling selected.')"
   ],
   "id": "c8d97ed504d3059b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Combine the resampled features and labels back into a single DataFrame\n",
    "full_data_resampled = pd.concat([X, y], axis=1)\n",
    "\n",
    "print(full_data_resampled.head())\n",
    "print(\"Resampled Data (SCALED):\")\n",
    "for label, code in class_codes.items():\n",
    "    # Print the first instance of each class\n",
    "    print(f\"First instance of {label} (code {code}):\")\n",
    "    print(full_data_resampled[full_data_resampled['33+1'] == code].iloc[0])\n",
    "\n",
    "full_data_resampled.head()"
   ],
   "id": "753802ea88e5d094",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Real vs Resampled Dataset Analysis",
   "id": "860e5742f94fe98a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "full_data_resampled.describe()",
   "id": "ddacca7fd78e8363",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "original_report = ProfileReport(full_data, title='Original Data', minimal=True)\n",
    "resampled_report = ProfileReport(full_data_resampled, title='Resampled Data', minimal=True)\n",
    "comparison_report = original_report.compare(resampled_report)\n",
    "comparison_report.to_file('./profile_reports/smote_original_vs_resampled.html')"
   ],
   "id": "5ee88dc4d8d6e4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluator Model",
   "id": "948bbb9fc2d8f028"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "51b74c5f6c7f1727"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ],
   "id": "cf2bfc6edba20a0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preprocessing\n",
    "### Scaling Numerical Features"
   ],
   "id": "c27d9d518268a164"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_cols = [\n",
    "    'flow_duration', 'Header_Length',  'Duration', 'Rate', 'Srate', 'ack_count', 'syn_count', 'fin_count',\n",
    "    'urg_count', 'rst_count', 'Tot sum', 'Min', 'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
    "    'Radius', 'Covariance', 'Variance', 'Weight'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "full_data_resampled[num_cols] = scaler.fit_transform(full_data_resampled[num_cols])"
   ],
   "id": "69f42708a2b55279",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Splitting",
   "id": "60309b19dd18cc27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = full_data_resampled.drop(['label', '33+1', '8+1', '1+1'], axis=1)\n",
    "y_all = full_data_resampled[['label', '33+1', '8+1', '1+1']]\n",
    "\n",
    "X_train, X_test, y_train_all, y_test_all = train_test_split(X, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = {}\n",
    "y_test = {}\n",
    "for _class in apply_classes:\n",
    "    y_train[_class] = y_train_all[_class]\n",
    "    y_test[_class] = y_test_all[_class]\n",
    "\n",
    "print(f'X_train: {X_train.shape}, y_train: {y_train['33+1'].shape}, X_test: {X_test.shape}, y_test: {y_test['33+1'].shape}')"
   ],
   "id": "606c4c4fe99d66f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "c002c0212202280f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for evaluator_type in apply_evaluators:\n",
    "    match evaluator_type:\n",
    "        case 'XGBoost':\n",
    "            from xgboost import XGBClassifier\n",
    "            evaluator = XGBClassifier()\n",
    "        case 'LogisticRegression':\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            evaluator = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "        case 'Perceptron':\n",
    "            from sklearn.linear_model import Perceptron\n",
    "            evaluator = Perceptron(random_state=42, n_jobs=-1)\n",
    "        case 'AdaBoost':\n",
    "            from sklearn.ensemble import AdaBoostClassifier\n",
    "            evaluator = AdaBoostClassifier(random_state=42, algorithm='SAMME')\n",
    "        case 'RandomForest':\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "            evaluator = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "        case 'DeepNeuralNetwork':\n",
    "            from sklearn.neural_network import MLPClassifier\n",
    "            evaluator = MLPClassifier(random_state=42)\n",
    "        case 'KNearestNeighbor':\n",
    "            from sklearn.neighbors import KNeighborsClassifier\n",
    "            evaluator = KNeighborsClassifier(n_jobs=-1)\n",
    "        case _:\n",
    "            print(f'Invalid evaluator model: {evaluator_type}')\n",
    "    \n",
    "    for _class in apply_classes:\n",
    "        print(f'{datetime.now()} : Training {evaluator_type} on {_class} classes')\n",
    "        evaluator.fit(X_train, y_train[_class])\n",
    "    \n",
    "        print(f'{datetime.now()} : Predicting {evaluator_type} on {_class} classes')\n",
    "        y_pred = evaluator.predict(X_test)\n",
    "    \n",
    "        print(f'{evaluator_type} {_class} Metrics')\n",
    "        print(f'   Accuracy: {accuracy_score(y_test[_class], y_pred)}')\n",
    "        print(f'   Precision: {precision_score(y_test[_class], y_pred, average='weighted', zero_division=0.0)}')\n",
    "        print(f'   Recall: {recall_score(y_test[_class], y_pred, average='weighted')}')\n",
    "        print(f'   F1: {f1_score(y_test[_class], y_pred, average='weighted')}')\n",
    "        print()"
   ],
   "id": "12c7e93dea6e6111",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Analysis",
   "id": "abba895894b40130"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, y_pred), columns = full_label_encoder.classes_)\n",
    "cm.insert(0, column='Actual', value=full_label_encoder.classes_)\n",
    "cm"
   ],
   "id": "d475e4995ea8ac0e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
